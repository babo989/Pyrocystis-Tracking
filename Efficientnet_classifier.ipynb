{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZsfvVnCg4lhhdytCLxDEu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/babo989/Pyrocystis-Tracking/blob/main/Efficientnet_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82vhWwdF11ZF"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "from PIL import UnidentifiedImageError\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import shutil\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\"\"\"\n",
        "Get the path to the cached TensorFlow Hub model and delete the cached directory\n",
        "\"\"\"\n",
        "\n",
        "model_cache_path = hub.resolve(\"https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\")\n",
        "shutil.rmtree(model_cache_path)\n",
        "\n",
        "\"\"\"\n",
        "URL for the EfficientNet B0 model from TensorFlow Hub\n",
        "\"\"\"\n",
        "\n",
        "model_url = \"https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\"\n",
        "\n",
        "\"\"\"\n",
        "Create a sequential model using the EfficientNet B0 model as the feature extractor\n",
        "and a dense layer with 6 output units (corresponding to the number of classes) and softmax activation\n",
        "\"\"\"\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "hub.KerasLayer(model_url, trainable=False),\n",
        "tf.keras.layers.Dense(6, activation='softmax')\n",
        "])\n",
        "\n",
        "\"\"\"\n",
        "Function to preprocess an image by resizing and normalizing pixel values\n",
        "\"\"\"\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "image = Image.open(image_path).convert(\"RGB\")\n",
        "image = image.resize((224, 224)) # EfficientNet input size\n",
        "image = np.array(image) / 255.0\n",
        "return image\n",
        "\n",
        "\"\"\"\n",
        "Dictionary mapping class names to numerical labels\n",
        "\"\"\"\n",
        "\n",
        "class_mapping = {'Dead': 0, 'Veg': 1, 'Div': 2, 'PreDiv': 3, 'Spore': 4, 'New': 5}\n",
        "\n",
        "\"\"\"\n",
        "Function to load image data and labels from a directory structure\n",
        "\"\"\"\n",
        "\n",
        "def load_data_from_folders(folder_path):\n",
        "data = []\n",
        "labels = []\n",
        "class_names = sorted(os.listdir(folder_path))\n",
        "for i, class_name in enumerate(class_names):\n",
        "if class_name == '.DS_Store':\n",
        "continue # Skip the .DS_Store file\n",
        "class_folder = os.path.join(folder_path, class_name)\n",
        "for image_file in os.listdir(class_folder):\n",
        "image_path = os.path.join(class_folder, image_file)\n",
        "try:\n",
        "image = preprocess_image(image_path)\n",
        "data.append(image)\n",
        "labels.append(class_mapping[class_name]) # Assign a label corresponding to the class index\n",
        "except (OSError, UnidentifiedImageError):\n",
        "print(f\"Skipping invalid image file: {image_path}\")\n",
        "return np.array(data), np.array(labels)\n",
        "\n",
        "\"\"\"\n",
        "Load data from the specified directory\n",
        "\"\"\"\n",
        "\n",
        "data, labels = load_data_from_folders(\"/Users/adam/Documents/Data/Planktoscope/Pyro_classifiertest/Classification\")\n",
        "\n",
        "\"\"\"\n",
        "Split the data into training/validation and test sets\n",
        "\"\"\"\n",
        "\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "\"\"\"\n",
        "Further split the training/validation set into separate training and validation sets\n",
        "\"\"\"\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, random_state=42)\n",
        "\n",
        "\"\"\"\n",
        "Create an instance of ImageDataGenerator for data augmentation\n",
        "\"\"\"\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "rotation_range=20,\n",
        "width_shift_range=0.2,\n",
        "height_shift_range=0.2,\n",
        "shear_range=0.2,\n",
        "zoom_range=0.2,\n",
        "horizontal_flip=True,\n",
        "fill_mode='nearest'\n",
        ")\n",
        "\n",
        "\"\"\"\n",
        "Compute statistics for data augmentation based on the training data\n",
        "\"\"\"\n",
        "\n",
        "datagen.fit(X_train)\n",
        "\n",
        "\"\"\"\n",
        "Compile the model with the specified loss function, optimizer, and metrics\n",
        "\"\"\"\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "\"\"\"\n",
        "Set the batch size and number of epochs\n",
        "\"\"\"\n",
        "\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "\n",
        "\"\"\"\n",
        "Train the model with data augmentation on the training set and evaluate on the validation set\n",
        "\"\"\"\n",
        "\n",
        "model.fit(datagen.flow(X_train, y_train, batch_size=batch_size), epochs=epochs, validation_data=(X_val, y_val))\n",
        "\n",
        "\"\"\"\n",
        "Evaluate the trained model on the test set\n",
        "\"\"\"\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "\n",
        "\"\"\"\n",
        "Function to classify objects in an image using the trained model\n",
        "\"\"\"\n",
        "\n",
        "def classify_objects(image_path, model):\n",
        "image = preprocess_image(image_path)\n",
        "image = np.expand_dims(image, axis=0)\n",
        "predictions = model.predict(image)\n",
        "class_index = np.argmax(predictions)\n",
        "return class_index, predictions\n",
        "\n",
        "\"\"\"\n",
        "Save the trained model to a file\n",
        "\"\"\"\n",
        "\n",
        "model.save(\"/Users/adam/Documents/Data/Planktoscope/Pyro_classifiertest/Classification4.h5\")\n",
        "\n",
        "\"\"\"\n",
        "Print a summary of the model architecture\n",
        "\"\"\"\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\"\"\"\n",
        "Print the unique class labels present in the dataset\n",
        "\"\"\"\n",
        "\n",
        "print(np.unique(labels))\n",
        "\n",
        "\"\"\"\n",
        "Example usage: classify an image\n",
        "\"\"\"\n",
        "\n",
        "image_path = \"/Users/adam/Documents/Data/Planktoscope/Pyro_classifiertest/10_28_14_574045_5.jpg\"\n",
        "class_index, predictions = classify_objects(image_path, model)\n",
        "print(\"Predicted class index:\", class_index)\n",
        "print(\"Class probabilities:\", predictions)"
      ]
    }
  ]
}